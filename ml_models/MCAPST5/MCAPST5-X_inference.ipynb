{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5D-q9BYzoVvO"
   },
   "source": [
    "### Check GPU hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRoY6MKt1aeI",
    "outputId": "a583466a-d3b1-4857-c9ef-214cb43dc409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 29 14:32:37 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.64.05              Driver Version: 575.64.05      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce MX550           Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   55C    P8              7W /   30W |       5MiB /   2048MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1148      G   /usr/lib/Xorg                             4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnuZk-s1piRk"
   },
   "source": [
    "### Install requirements for ProtBert embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyQ4uyiWphmv",
    "outputId": "200ec83b-fa7d-4890-f6f8-3733e41a18e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (4.29.2)\n",
      "Requirement already satisfied: sentencepiece in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: h5py in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (0.33.5)\n",
      "Requirement already satisfied: filelock in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: requests in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (1.1.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2025.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from requests->transformers) (2025.7.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQZ5i52i3oMH",
    "outputId": "18767b02-4ddf-4a09-fb21-7d307d2623cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from torch==1.9.0+cu111) (4.14.1)\n",
      "Requirement already satisfied: numpy in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from torchvision==0.10.0+cu111) (1.24.4)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages (from torchvision==0.10.0+cu111) (11.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBsAQxOcpxj-"
   },
   "source": [
    "### Set up embedding directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7xhz60CprsI",
    "outputId": "4eab0270-04b0-4394-e17c-7591a2bfa031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘protT5’: File exists\n",
      "mkdir: cannot create directory ‘protT5/protT5_checkpoint’: File exists\n",
      "mkdir: cannot create directory ‘protT5/sec_struct_checkpoint’: File exists\n",
      "mkdir: cannot create directory ‘protT5/output’: File exists\n",
      "--2025-07-29 14:32:40--  https://rostlab.org/~deepppi/example_seqs.fasta\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving rostlab.org (rostlab.org)... 104.21.38.66, 172.67.219.184, 2606:4700:3030::ac43:dbb8, ...\n",
      "Connecting to rostlab.org (rostlab.org)|104.21.38.66|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://files.rostlab.org/~deepppi/example_seqs.fasta [following]\n",
      "--2025-07-29 14:32:41--  https://files.rostlab.org/~deepppi/example_seqs.fasta\n",
      "Resolving files.rostlab.org (files.rostlab.org)... 131.159.28.73\n",
      "Connecting to files.rostlab.org (files.rostlab.org)|131.159.28.73|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /deepppi/example_seqs.fasta [following]\n",
      "--2025-07-29 14:32:42--  https://files.rostlab.org/deepppi/example_seqs.fasta\n",
      "Reusing existing connection to files.rostlab.org:443.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2025-07-29 14:32:42 ERROR 404: Not Found.\n",
      "\n",
      "File ‘protT5/sec_struct_checkpoint/secstruct_checkpoint.pt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create directory for storing model weights (2.3GB) and example sequences.\n",
    "# Here we use the encoder-part of ProtT5-XL-U50 in half-precision (fp16) as \n",
    "# it performed best in our benchmarks (also outperforming ProtBERT-BFD).\n",
    "# Also download secondary structure prediction checkpoint to show annotation extraction from embeddings\n",
    "!mkdir protT5 # root directory for storing checkpoints, results etc\n",
    "!mkdir protT5/protT5_checkpoint # directory holding the ProtT5 checkpoint\n",
    "!mkdir protT5/sec_struct_checkpoint # directory storing the supervised classifier's checkpoint\n",
    "!mkdir protT5/output # directory for storing your embeddings & predictions\n",
    "!wget -nc -P protT5/ https://rostlab.org/~deepppi/example_seqs.fasta\n",
    "# Huge kudos to the bio_embeddings team here! We will integrate the new encoder, half-prec ProtT5 checkpoint soon\n",
    "!wget -nc -P protT5/sec_struct_checkpoint http://data.bioembeddings.com/public/embeddings/feature_models/t5/secstruct_checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpVKvCU2sfge"
   },
   "source": [
    "### Download interaction, dictionary/fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cTGEFmip9Na",
    "outputId": "3440cd3c-ecf4-4323-b3e4-258da3f85435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have the dictionary and pair files\n"
     ]
    }
   ],
   "source": [
    "# Yous should change for the test dataset you want to evaluate on\n",
    "import os\n",
    "pair_path = 'ecoli_test.tsv'\n",
    "seq_path = 'ecoli.fasta'\n",
    "\n",
    "\n",
    "if os.path.isfile(seq_path) == False or os.path.isfile(pair_path) == False:\n",
    "  !wget https://raw.githubusercontent.com/anhvt00/MCAPS/master/data/Dscript-data/pairs/ecoli_test.tsv\n",
    "  !wget https://raw.githubusercontent.com/anhvt00/MCAPS/master/data/Dscript-data/seqs/ecoli.fasta\n",
    "    \n",
    "else:\n",
    "  print(\"Already have the dictionary and pair files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUrwC7uGp22f"
   },
   "source": [
    "### Choose sequence FASTA file for embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "u0bzK4mbqCyF"
   },
   "outputs": [],
   "source": [
    "# In the following you can define your desired output. Current options:\n",
    "# per_residue embeddings\n",
    "# per_protein embeddings\n",
    "# secondary structure predictions\n",
    "\n",
    "# Replace this file with your own (multi-)FASTA\n",
    "# Headers are expected to start with \">\";\n",
    "# seq_path = \"guo.fasta\"\n",
    "\n",
    "# whether to retrieve embeddings for each residue in a protein \n",
    "# --> Lx1024 matrix per protein with L being the protein's length\n",
    "# as a rule of thumb: 1k proteins require around 1GB RAM/disk\n",
    "per_residue = True \n",
    "per_residue_path = \"./protT5/output/per_residue_embeddings.h5\" # where to store the embeddings\n",
    "\n",
    "# whether to retrieve per-protein embeddings \n",
    "# --> only one 1024-d vector per protein, irrespective of its length\n",
    "per_protein = False\n",
    "per_protein_path = \"./protT5/output/per_protein_embeddings.h5\" # where to store the embeddings\n",
    "\n",
    "# whether to retrieve secondary structure predictions\n",
    "# This can be replaced by your method after being trained on ProtT5 embeddings\n",
    "sec_struct = False\n",
    "sec_struct_path = \"./protT5/output/ss3_preds.fasta\" # file for storing predictions\n",
    "\n",
    "# make sure that either per-residue or per-protein embeddings are stored\n",
    "assert per_protein is True or per_residue is True or sec_struct is True, print(\n",
    "    \"Minimally, you need to active per_residue, per_protein or sec_struct. (or any combination)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckj3UjxyrEdm"
   },
   "source": [
    "### Read FASTA file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BQ9zpehyqrtv"
   },
   "outputs": [],
   "source": [
    "def read_fasta( fasta_path, split_char=\"!\", id_field=0):\n",
    "    '''\n",
    "        Reads in fasta file containing multiple sequences.\n",
    "        Split_char and id_field allow to control identifier extraction from header.\n",
    "        E.g.: set split_char=\"|\" and id_field=1 for SwissProt/UniProt Headers.\n",
    "        Returns dictionary holding multiple sequences or only single \n",
    "        sequence, depending on input file.\n",
    "    '''\n",
    "    \n",
    "    seqs = dict()\n",
    "    with open( fasta_path, 'r' ) as fasta_f:\n",
    "        for line in fasta_f:\n",
    "            # get uniprot ID from header and create new entry\n",
    "            if line.startswith('>'):\n",
    "                uniprot_id = line.replace('>', '').strip().split(split_char)[id_field]\n",
    "                # replace tokens that are mis-interpreted when loading h5\n",
    "                uniprot_id = uniprot_id.replace(\"/\",\"_\").replace(\".\",\"_\")\n",
    "                seqs[ uniprot_id ] = ''\n",
    "            else:\n",
    "                # repl. all whie-space chars and join seqs spanning multiple lines, drop gaps and cast to upper-case\n",
    "                seq= ''.join( line.split() ).upper().replace(\"-\",\"\")\n",
    "                # repl. all non-standard AAs and map them to unknown/X\n",
    "                seq = seq.replace('U','X').replace('Z','X').replace('O','X')\n",
    "                seqs[ uniprot_id ] += seq \n",
    "    example_id=next(iter(seqs))\n",
    "    print(\"Read {} sequences.\".format(len(seqs)))\n",
    "    print(\"Example:\\n{}\\n{}\".format(example_id,seqs[example_id]))\n",
    "\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEL1Q_TkqR2Y"
   },
   "source": [
    "### Import ProtBert embedder model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnnYiMSSqQ_G",
    "outputId": "6fcd0967-f2ab-4ff1-d287-5f7d4fe2b0fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(\"Using {}\".format(device))\n",
    "\n",
    "def get_T5_model():\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "    model = model.to(device) # move model to GPU\n",
    "    model = model.eval() # set model to evaluation model\n",
    "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF-_BqblrOPq"
   },
   "source": [
    "### Generate embeddings function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FaAQNEs8qZw4"
   },
   "outputs": [],
   "source": [
    "# Generate embeddings via batch-processing\n",
    "# per_residue indicates that embeddings for each residue in a protein should be returned.\n",
    "# per_protein indicates that embeddings for a whole protein should be returned (average-pooling)\n",
    "# max_residues gives the upper limit of residues within one batch\n",
    "# max_seq_len gives the upper sequences length for applying batch-processing\n",
    "# max_batch gives the upper number of sequences per batch\n",
    "def get_embeddings( model, tokenizer, seqs, per_residue, per_protein, sec_struct, \n",
    "                   max_residues=4000, max_seq_len=1000, max_batch=100 ):\n",
    "\n",
    "    if sec_struct:\n",
    "      sec_struct_model = load_sec_struct_model()\n",
    "\n",
    "    results = {\"residue_embs\" : dict(), \n",
    "               \"protein_embs\" : dict(),\n",
    "               \"sec_structs\" : dict() \n",
    "               }\n",
    "\n",
    "    # sort sequences according to length (reduces unnecessary padding --> speeds up embedding)\n",
    "    seq_dict   = sorted( seqs.items(), key=lambda kv: len( seqs[kv[0]] ), reverse=True )\n",
    "    start = time.time()\n",
    "    batch = list()\n",
    "    for seq_idx, (pdb_id, seq) in tqdm(enumerate(seq_dict,1)):\n",
    "        seq = seq\n",
    "        seq_len = len(seq)\n",
    "        seq = ' '.join(list(seq))\n",
    "        batch.append((pdb_id,seq,seq_len))\n",
    "\n",
    "        # count residues in current batch and add the last sequence length to\n",
    "        # avoid that batches with (n_res_batch > max_residues) get processed \n",
    "        n_res_batch = sum([ s_len for  _, _, s_len in batch ]) + seq_len \n",
    "        if len(batch) >= max_batch or n_res_batch>=max_residues or seq_idx==len(seq_dict) or seq_len>max_seq_len:\n",
    "            pdb_ids, seqs, seq_lens = zip(*batch)\n",
    "            batch = list()\n",
    "\n",
    "            # add_special_tokens adds extra token at the end of each sequence\n",
    "            token_encoding = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
    "            input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
    "            attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
    "            \n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
    "                    embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
    "            except RuntimeError:\n",
    "                print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
    "                continue\n",
    "\n",
    "            if sec_struct: # in case you want to predict secondary structure from embeddings\n",
    "              d3_Yhat, d8_Yhat, diso_Yhat = sec_struct_model(embedding_repr.last_hidden_state)\n",
    "\n",
    "\n",
    "            for batch_idx, identifier in enumerate(pdb_ids): # for each protein in the current mini-batch\n",
    "                s_len = seq_lens[batch_idx]\n",
    "                # slice off padding --> batch-size x seq_len x embedding_dim  \n",
    "                emb = embedding_repr.last_hidden_state[batch_idx,:s_len]\n",
    "                if sec_struct: # get classification results\n",
    "                    results[\"sec_structs\"][identifier] = torch.max( d3_Yhat[batch_idx,:s_len], dim=1 )[1].detach().cpu().numpy().squeeze()\n",
    "                if per_residue: # store per-residue embeddings (Lx1024)\n",
    "                    results[\"residue_embs\"][ identifier ] = emb.detach().cpu().numpy().squeeze()\n",
    "                if per_protein: # apply average-pooling to derive per-protein embeddings (1024-d)\n",
    "                    protein_emb = emb.mean(dim=0)\n",
    "                    results[\"protein_embs\"][identifier] = protein_emb.detach().cpu().numpy().squeeze()\n",
    "\n",
    "\n",
    "    passed_time=time.time()-start\n",
    "    avg_time = passed_time/len(results[\"residue_embs\"]) if per_residue else passed_time/len(results[\"protein_embs\"])\n",
    "    print('\\n############# EMBEDDING STATS #############')\n",
    "    print('Total number of per-residue embeddings: {}'.format(len(results[\"residue_embs\"])))\n",
    "    print('Total number of per-protein embeddings: {}'.format(len(results[\"protein_embs\"])))\n",
    "    print(\"Time for generating embeddings: {:.1f}[m] ({:.3f}[s/protein])\".format(\n",
    "        passed_time/60, avg_time ))\n",
    "    print('\\n############# END #############')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16chLbRYrbmn"
   },
   "source": [
    "### Write embeddings to disk function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0WsvghwRrZdf"
   },
   "outputs": [],
   "source": [
    "def save_embeddings(emb_dict,out_path):\n",
    "    with h5py.File(str(out_path), \"w\") as hf:\n",
    "        for sequence_id, embedding in emb_dict.items():\n",
    "            # noinspection PyUnboundLocalVariable\n",
    "            hf.create_dataset(sequence_id, data=embedding)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee18ICHsryMg"
   },
   "source": [
    "### Generate embedding for FASTA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CMYqWvA7roEf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiennd/.pyenv/versions/3.9.18/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 1.64 GiB total capacity; 448.52 MiB already allocated; 62.50 MiB free; 450.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(per_residue_path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Load the encoder part of ProtT5-XL-U50 in half-precision (recommended)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mget_T5_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Load example fasta.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     seqs \u001b[38;5;241m=\u001b[39m read_fasta( seq_path )\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mget_T5_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_T5_model\u001b[39m():\n\u001b[1;32m     11\u001b[0m     model \u001b[38;5;241m=\u001b[39m T5EncoderModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRostlab/prot_t5_xl_half_uniref50-enc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# move model to GPU\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# set model to evaluation model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRostlab/prot_t5_xl_half_uniref50-enc\u001b[39m\u001b[38;5;124m'\u001b[39m, do_lower_case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/transformers/modeling_utils.py:1878\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1874\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1875\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1876\u001b[0m     )\n\u001b[1;32m   1877\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torch/nn/modules/module.py:852\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    849\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torch/nn/modules/module.py:530\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 530\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    535\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torch/nn/modules/module.py:530\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 530\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    535\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 530 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torch/nn/modules/module.py:530\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 530\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    535\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torch/nn/modules/module.py:552\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 552\u001b[0m         param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/lib/python3.9/site-packages/torch/nn/modules/module.py:850\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    849\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 850\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 1.64 GiB total capacity; 448.52 MiB already allocated; 62.50 MiB free; 450.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(per_residue_path) == False:\n",
    "    # Load the encoder part of ProtT5-XL-U50 in half-precision (recommended)\n",
    "    model, tokenizer = get_T5_model()\n",
    "\n",
    "    # Load example fasta.\n",
    "    seqs = read_fasta( seq_path )\n",
    "\n",
    "    for id, seq in seqs.items():\n",
    "        if len(seq) > 1200:\n",
    "            seqs[id] = seq[:1200]\n",
    "\n",
    "\n",
    "    # Compute embeddings and/or secondary structure predictions\n",
    "    results = get_embeddings( model, tokenizer, seqs,\n",
    "                             per_residue, per_protein, sec_struct)\n",
    "\n",
    "    # Store per-residue embeddings\n",
    "    if per_residue:\n",
    "      save_embeddings(results[\"residue_embs\"], per_residue_path)\n",
    "    if per_protein:\n",
    "      save_embeddings(results[\"protein_embs\"], per_protein_path)\n",
    "else:\n",
    "    print(\"Already have the embedding file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lxQjjPnoY02"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1QbuwzCoao2",
    "outputId": "0a69579a-ac80-409f-d656-3d6027dae3c8"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "!pip install matplotlib\n",
    "!apt install wget\n",
    "!pip install scikit-learn pandas \n",
    "!pip install gdown\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import math\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization, ReLU, LeakyReLU, Conv1D, GlobalMaxPooling1D, AveragePooling1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import concatenate, multiply, Bidirectional, LSTM, GRU, Flatten, PReLU, add, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2, l1_l2\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef,accuracy_score, precision_score,recall_score\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import mixed_precision\n",
    "!pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "### Setting RAM GPU for training growth \n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "# Disables caching (when set to 1) or enables caching (when set to 0) for just-in-time-compilation. When disabled,\n",
    "# no binary code is added to or retrieved from the cache.\n",
    "os.environ['CUDA_CACHE_DISABLE'] = '0' # orig is 0\n",
    "\n",
    "# When set to 1, forces the device driver to ignore any binary code embedded in an application \n",
    "# (see Application Compatibility) and to just-in-time compile embedded PTX code instead.\n",
    "# If a kernel does not have embedded PTX code, it will fail to load. This environment variable can be used to\n",
    "# validate that PTX code is embedded in an application and that its just-in-time compilation works as expected to guarantee application \n",
    "# forward compatibility with future architectures.\n",
    "os.environ['CUDA_FORCE_PTX_JIT'] = '1'# no orig\n",
    "\n",
    "\n",
    "os.environ['HOROVOD_GPU_ALLREDUCE'] = 'NCCL'\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT']='1'\n",
    "\n",
    "os.environ['TF_USE_CUDNN_BATCHNORM_SPATIAL_PERSISTENT'] = '1'\n",
    "\n",
    "os.environ['TF_ADJUST_HUE_FUSED'] = '1'\n",
    "os.environ['TF_ADJUST_SATURATION_FUSED'] = '1'\n",
    "os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
    "\n",
    "os.environ['TF_SYNC_ON_FINISH'] = '0'\n",
    "os.environ['TF_AUTOTUNE_THRESHOLD'] = '2'\n",
    "os.environ['TF_DISABLE_NVTX_RANGES'] = '1'\n",
    "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION_GRAPH_REWRITE\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "# =================================================\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "## Set constant hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "seq_size = 1200\n",
    "dim = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmYDhhxz-Nd6"
   },
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "625chb3e-R2W"
   },
   "outputs": [],
   "source": [
    "print(\"Load the embedding file\")\n",
    "embedding_matrix= h5py.File(per_residue_path, 'r')\n",
    "protein_keys = list(embedding_matrix.keys())\n",
    "embedding_dict = dict()\n",
    "\n",
    "for key in tqdm(protein_keys):\n",
    "  embedding_dict[key] = np.array(embedding_matrix[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1DKoGKXsQvK"
   },
   "source": [
    "### Read interaction dataset to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "_5XAIYkKsXPW",
    "outputId": "77ae6601-015c-44a5-d0d1-bb230ad962ca"
   },
   "outputs": [],
   "source": [
    "print(\"Load the pair dataset file\")\n",
    "pair_dataframe = pd.read_csv(pair_path, sep='\\t', header=None)\n",
    "pair_array  = pair_dataframe.to_numpy()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(pair_array)\n",
    "pair_dataframe = pd.DataFrame(pair_array)\n",
    "pair_dataframe = pd.DataFrame(pair_array, columns = ['p1', 'p2', 'label'])\n",
    "pair_dataframe['label'] = pair_dataframe['label'].astype('float16') \n",
    "pair_dataframe['p1'] = pair_dataframe['p1'].str.replace(\".\",\"_\")\n",
    "pair_dataframe['p2'] = pair_dataframe['p2'].str.replace(\".\",\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWnhEFD5xXNl"
   },
   "source": [
    "### Padding function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koiIBavgWWeT"
   },
   "outputs": [],
   "source": [
    "def pad(rst, length=1200, dim=1024):\n",
    "    if len(rst) > length:\n",
    "        return rst[:length]\n",
    "    elif len(rst) < length:\n",
    "        return np.concatenate((rst, np.zeros((length - len(rst), dim))))\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-mBPjEe1P_X"
   },
   "source": [
    "### Read embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUl-7v161P_x"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "embedding_matrix= h5py.File(per_residue_path, 'r')\n",
    "protein_keys = list(embedding_matrix.keys())\n",
    "embedding_dict = dict()\n",
    "\n",
    "for key in protein_keys:\n",
    "  embedding_dict[key] = np.array(embedding_matrix[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYfGXeeO-wkY"
   },
   "source": [
    "### Function for mapping in dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "z56kdY0f-wke"
   },
   "outputs": [],
   "source": [
    "def func(i):\n",
    "    i = i.numpy() # Decoding from the EagerTensor object\n",
    "    x1= pad(embedding_dict[pair_dataframe['p1'][i]])\n",
    "    x2= pad(embedding_dict[pair_dataframe['p2'][i]])\n",
    "    y = pair_dataframe['label'][i]\n",
    "    return x1, x2, y\n",
    "\n",
    "def _fixup_shape(x1, x2, y):\n",
    "    x1.set_shape((seq_size, dim))\n",
    "    x2.set_shape((seq_size, dim)) \n",
    "    y.set_shape(()) \n",
    "\n",
    "    return (x1, x2), y\n",
    "\n",
    "def pad(rst, length=1200, dim=1024):\n",
    "    if len(rst) > length:\n",
    "        return rst[:length]\n",
    "    elif len(rst) < length:\n",
    "        return np.concatenate((rst, np.zeros((length - len(rst), dim))))\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the test dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_generator(lambda: range(len(pair_dataframe)), tf.uint64).map(lambda i: tf.py_function(func=func, \n",
    "                                              inp=[i], \n",
    "                                              Tout=[tf.float16,\n",
    "                                                    tf.float16, tf.float16]\n",
    "                                              ), \n",
    "                      num_parallel_calls=tf.data.AUTOTUNE).map(_fixup_shape).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMoeBQnUCK_E"
   },
   "source": [
    "### Architecture of MCAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iY1Qm9AjmIaO",
    "outputId": "6e0d8050-74b0-4c3f-a652-491480b44501"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_custom_objects\n",
    "def leaky_relu(x, alpha = .2):\n",
    "   return tf.keras.backend.maximum(alpha*x, x)\n",
    "!pip install tensorflow-addons\n",
    "import tensorflow_addons as tfa \n",
    "get_custom_objects().update({'leaky_relu': leaky_relu})\n",
    "get_custom_objects().update({'mish': tfa.activations.mish})\n",
    "get_custom_objects().update({'lisht': tfa.activations.lisht})\n",
    "get_custom_objects().update({'rrelu': tfa.activations.rrelu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwUkDkHjsJ1c",
    "outputId": "64108f8a-a88b-40fb-b74a-96a149a48a15"
   },
   "outputs": [],
   "source": [
    "seq_size = 1200\n",
    "dim = 1024\n",
    "def multi_cnn():\n",
    "    DEPTH = 5\n",
    "    WIDTH = 3\n",
    "    POOLING_SIZE = 4\n",
    "    FILTERS = 50\n",
    "    KERNEL_SIZE = 2\n",
    "    DEPTH_DENSE1 = 3\n",
    "    DEPTH_DENSE2 = 2\n",
    "    DROPOUT = DROPOUT1 = DROPOUT2 = 0.05\n",
    "    DROPOUT_SPATIAL= 0.15\n",
    "    ACTIVATION = 'swish'\n",
    "    ACTIVATION_CNN = 'swish'\n",
    "    INITIALIZER = 'glorot_normal'\n",
    "    \n",
    "    def BlockCNN_single(KERNEL_SIZE, POOLING_SIZE, FILTERS, LAYER_IN1, LAYER_IN2):\n",
    "        c1 = Conv1D(filters=FILTERS, kernel_size=KERNEL_SIZE, activation=ACTIVATION_CNN, padding='same')\n",
    "        x1 = c1(LAYER_IN1)\n",
    "        x2 = c1(LAYER_IN2)\n",
    "\n",
    "        g1 = Dropout(DROPOUT)(concatenate([GlobalMaxPooling1D()(x1),GlobalAveragePooling1D()(x1)]))\n",
    "        a1 = GlobalAveragePooling1D()(x1)\n",
    "        g2 = Dropout(DROPOUT)(concatenate([GlobalMaxPooling1D()(x2),GlobalAveragePooling1D()(x2)]))\n",
    "        a2 = GlobalAveragePooling1D()(x1)\n",
    "\n",
    "        x1 = SpatialDropout1D(DROPOUT_SPATIAL)(concatenate([MaxPooling1D(POOLING_SIZE)(x1), AveragePooling1D(POOLING_SIZE)(x1)]))\n",
    "        x2 = SpatialDropout1D(DROPOUT_SPATIAL)(concatenate([MaxPooling1D(POOLING_SIZE)(x2), AveragePooling1D(POOLING_SIZE)(x2)]))\n",
    "\n",
    "        return x1, x2, g1, g2, a1, a2\n",
    "\n",
    "    def BlockCNN_multi(POOLING_SIZE, FILTERS, LAYER_IN1, LAYER_IN2, WIDTH):\n",
    "      X1 = []\n",
    "      X2 = []\n",
    "      G1 = []\n",
    "      G2 = []\n",
    "      A1 = []\n",
    "      A2 = []\n",
    "      for i in range(2, 2+WIDTH):\n",
    "        x1, x2, g1, g2, a1, a2 = BlockCNN_single(i, POOLING_SIZE, FILTERS, LAYER_IN1, LAYER_IN2)\n",
    "        X1.append(x1)\n",
    "        X2.append(x2)\n",
    "        G1.append(g1)\n",
    "        G2.append(g2)\n",
    "        A1.append(a1)\n",
    "        A2.append(a2)\n",
    "      x1 = concatenate(X1)\n",
    "      x2 = concatenate(X2)\n",
    "      g1 = GlobalMaxPooling1D()(x1)\n",
    "      g2 = GlobalMaxPooling1D()(x2)\n",
    "      return x1, x2, g1, g2\n",
    "\n",
    "    def BlockCNN_single_deep(KERNEL_SIZE, POOLING_SIZE, DEPTH, FILTERS, LAYER_IN1, LAYER_IN2):\n",
    "      X1 = []\n",
    "      X2 = []\n",
    "      G1 = []\n",
    "      G2 = []\n",
    "      A1 = []\n",
    "      A2 = []\n",
    "      x1 = LAYER_IN1\n",
    "      x2 = LAYER_IN2\n",
    "      for i in range(DEPTH):\n",
    "        x1, x2, g1, g2, a1, a2 = BlockCNN_single(KERNEL_SIZE, POOLING_SIZE, FILTERS, x1, x2)\n",
    "        X1.append(x1)\n",
    "        X2.append(x2)\n",
    "        G1.append(g1)\n",
    "        G2.append(g2)\n",
    "        A1.append(a1)\n",
    "        A2.append(a2)\n",
    "\n",
    "      return X1, X2, G1, G2, A1, A2\n",
    "\n",
    "    input1 = Input(shape=(seq_size, dim), name=\"seq1\")\n",
    "    input2 = Input(shape=(seq_size, dim), name=\"seq2\")\n",
    "    \n",
    "\n",
    "\n",
    "    X1 = dict()\n",
    "    X2 = dict()\n",
    "    G1 = dict()\n",
    "    G2 = dict()\n",
    "    A1 = dict()\n",
    "    A2 = dict()\n",
    "\n",
    "    for i in range(KERNEL_SIZE, KERNEL_SIZE+WIDTH):\n",
    "      X1[f'{i}'], X2[f'{i}'], G1[f'{i}'], G2[f'{i}'], A1[f'{i}'], A2[f'{i}'] = BlockCNN_single_deep(i, POOLING_SIZE, DEPTH, FILTERS, input1, input2)\n",
    "\n",
    "    s1 = []\n",
    "    s2 = []\n",
    "    for i in range(KERNEL_SIZE, KERNEL_SIZE+WIDTH):\n",
    "      s1.extend(G1[f'{i}'])\n",
    "      s2.extend(G2[f'{i}'])\n",
    "\n",
    "    s1 = concatenate(s1)\n",
    "    s2 = concatenate(s2)\n",
    "    \n",
    "    s1 = BatchNormalization(momentum=.9)(s1)\n",
    "    s2 = BatchNormalization(momentum=.9)(s2)\n",
    "\n",
    "    s1 = Dropout(DROPOUT1)(s1)\n",
    "    s2 = Dropout(DROPOUT1)(s2)\n",
    "    \n",
    "    s1_shape = s1.shape[-1]\n",
    "    DENSE1 = 744 \n",
    "    d1 = []\n",
    "    for i in range(DEPTH_DENSE1):\n",
    "        d1.append(Dense(int(DENSE1*(1/2)**i), kernel_initializer=INITIALIZER, activation=ACTIVATION))\n",
    "\n",
    "    for i in range(DEPTH_DENSE1):\n",
    "        s1 = d1[i](s1)\n",
    "        s2 = d1[i](s2)\n",
    "        s1 = Dropout(DROPOUT1)(s1)\n",
    "        s2 = Dropout(DROPOUT1)(s2)\n",
    "        \n",
    "    s = concatenate([s1, s2])\n",
    "\n",
    "    \n",
    "    s_shape = s.shape[-1]\n",
    "    DENSE2 = 328\n",
    "        \n",
    "    d2 = []\n",
    "    for i in range(DEPTH_DENSE2):\n",
    "        d2.append(Dense(int(DENSE2*(1/2)**i), kernel_initializer=INITIALIZER, activation=ACTIVATION))\n",
    "\n",
    "    for i in range(DEPTH_DENSE2):\n",
    "        s = d2[i](s)\n",
    "        s = Dropout(DROPOUT2)(s)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(s)\n",
    "    model = Model(inputs=[input1, input2], outputs=[output])\n",
    "    \n",
    "    adabelief = tfa.optimizers.AdaBelief(\n",
    "    rectify=False,\n",
    "    epsilon=1e-8)\n",
    "    adam = Adam(learning_rate=1e-3, amsgrad=True, epsilon=1e-6)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = multi_cnn()\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose another checkpoint, the default is epoch 20 for both datasets Pan and Sled\n",
    "!wget https://github.com/anhvt00/MCAPS/raw/master/checkpoint/Pan/mcapst5_pan_epoch_20.hdf5\n",
    "!wget https://github.com/anhvt00/MCAPS/raw/master/checkpoint/Pan/xgboost_pan_epoch_20.bin\n",
    "\n",
    "checkpoint_mcapst5 = \"mcapst5_pan_epoch_20.hdf5\"\n",
    "checkpoint_xgboost = \"xgboost_pan_epoch_20.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(checkpoint_mcapst5)\n",
    "model_ = XGBClassifier()\n",
    "model_.load_model(checkpoint_xgboost) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the test dataset with MCAPST5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)\n",
    "y_true = pair_dataframe['label'].values\n",
    "cm1=confusion_matrix(y_true, np.round(y_pred))\n",
    "acc = (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])\n",
    "spec= (cm1[0,0])/(cm1[0,0]+cm1[0,1])\n",
    "sens = (cm1[1,1])/(cm1[1,0]+cm1[1,1])\n",
    "prec=cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "rec=cm1[1,1]/(cm1[1,1]+cm1[1,0])\n",
    "f1 = 2 * (prec * rec) / (prec + rec)\n",
    "mcc = matthews_corrcoef(y_true, np.round(y_pred))\n",
    "\n",
    "prc = metrics.average_precision_score(y_true, y_pred)\n",
    "\n",
    "print(\"============= INFERENCE BY NEURAL NETWORK ===============\")\n",
    "try:\n",
    "  auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "  print(f'accuracy: {acc}, precision: {prec}, recall: {rec}, specificity: {spec}, f1-score: {f1}, mcc: {mcc}, auroc: {auc}, auprc: {prc} ')\n",
    "  print(str(acc) + \"\\t\" + str(prec) + \"\\t\" + str(rec) + \"\\t\" + str(spec) + \"\\t\" + str(f1) + \"\\t\" + str(mcc)+\"\\t\" + str(auc)  + \"\\t\" + str(prc) + \"\\n\")\n",
    "except ValueError:\n",
    "  print(f'accuracy: {acc}, precision: {prec}, recall: {rec}, specificity: {spec}, f1-score: {f1}, mcc: {mcc}, auroc: nan, auprc: {prc} ')\n",
    "  print(str(acc) + \"\\t\" + str(prec) + \"\\t\" + str(rec) + \"\\t\" + str(spec) + \"\\t\" + str(f1) + \"\\t\" + str(mcc)+\"\\t nan\"  + \"\\t\" + str(prc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit XGBoost for learned representations from MCAPST5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=model.input,outputs=model.get_layer(model.layers[-2].name).output)\n",
    "\n",
    "# Use intermediate layer to transform pairs matrix\n",
    "pred = intermediate_layer_model.predict(test_dataset)\n",
    "p_merge=pd.DataFrame(pred)    \n",
    "Trainlabels = pair_dataframe['label']\n",
    "# create dataframe use transformed pairs matrix outputs and labels\n",
    "X_train_feat=pd.concat((p_merge,pd.DataFrame(pd.DataFrame(Trainlabels))),axis=1,ignore_index=True)\n",
    "\n",
    "# write to file dataframe of transformed pairs matrix and labels\n",
    "X_train_feat.to_csv('X_train.csv',header=False, index=False)\n",
    "\n",
    "# read dataframe of transformed pairs matrix and labels\n",
    "Train=pd.read_csv(\"X_train.csv\",header=None)\n",
    "# Train=Train.sample(frac=1)\n",
    "\n",
    "shape_x = model.layers[-2].get_output_at(0).get_shape()[1]\n",
    "X=Train.iloc[:,0:shape_x].values\n",
    "y=Train.iloc[:,shape_x:].values\n",
    "\n",
    "extracted_df=X_train_feat\n",
    "\n",
    "\n",
    "y = y.reshape(-1, )\n",
    "model_= XGBClassifier(booster='gbtree', reg_lambda=1, alpha=1e-7, subsample=0.8, colsample_bytree=0.2, n_estimators=100, max_depth=5, min_child_weight=2, gamma=1e-7, eta=1e-6)\n",
    "model_.fit(X, y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the test dataset with MCAPST5-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_.predict(X)\n",
    "y_true = y\n",
    "cm1=confusion_matrix(y_true, np.round(y_pred))\n",
    "acc = (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])\n",
    "spec= (cm1[0,0])/(cm1[0,0]+cm1[0,1])\n",
    "sens = (cm1[1,1])/(cm1[1,0]+cm1[1,1])\n",
    "prec=cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "rec=cm1[1,1]/(cm1[1,1]+cm1[1,0])\n",
    "f1 = 2 * (prec * rec) / (prec + rec)\n",
    "mcc = matthews_corrcoef(y_true, np.round(y_pred))\n",
    "\n",
    "prc = metrics.average_precision_score(y_true, y_pred)\n",
    "\n",
    "print(\"============= INFERENCE BY HYBRID MODEL ===============\")\n",
    "try:\n",
    "  auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "  print(f'accuracy: {acc}, precision: {prec}, recall: {rec}, specificity: {spec}, f1-score: {f1}, mcc: {mcc}, auroc: {auc}, auprc: {prc} ')\n",
    "  print(str(acc) + \"\\t\" + str(prec) + \"\\t\" + str(rec) + \"\\t\" + str(spec) + \"\\t\" + str(f1) + \"\\t\" + str(mcc)+\"\\t\" + str(auc)  + \"\\t\" + str(prc) + \"\\n\")\n",
    "except ValueError:\n",
    "  print(f'accuracy: {acc}, precision: {prec}, recall: {rec}, specificity: {spec}, f1-score: {f1}, mcc: {mcc}, auroc: nan, auprc: {prc} ')\n",
    "  print(str(acc) + \"\\t\" + str(prec) + \"\\t\" + str(rec) + \"\\t\" + str(spec) + \"\\t\" + str(f1) + \"\\t\" + str(mcc)+\"\\t nan\"  + \"\\t\" + str(prc) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
